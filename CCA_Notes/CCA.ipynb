{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCA\n",
    "\n",
    "canonical correlation analysis\n",
    "\n",
    "Let $X^{(1)}$ be a p by 1 vector and $X^{(2)}$ be a q by 1 vector, $p<=q$\n",
    "\n",
    "Let $E(X^{1}) = \\mu^1_{(p*1)}; Cov(X^1) = \\Sigma_{11(p*p)}$\n",
    "$E(X^{2}) = \\mu^2_{(q*1)}; Cov(X^2) = \\Sigma_{22(q*q)}$\n",
    "\n",
    "and\n",
    "\n",
    "$Cov(X^1,X^2) = \\Sigma_{12} = \\Sigma_{21}^T$,\n",
    "$E[[X^1 - \\mu^1][X^2 - \\mu^2]^T]$ is a p by q matrix.\n",
    "\n",
    "So:\n",
    "\n",
    "<img src=\"ex.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "<img src=\"cov.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Set linear combinations:\n",
    "$U=a^T X^1, V = b^TX^2$\n",
    "\n",
    "We can obtain:\n",
    "\\begin{align*}\n",
    "Var(U) &= a^T Cov(X^1)a = a^T \\Sigma_{11}a\\\\\n",
    "Var(V) &= b^T Cov(X^2)b = b^T \\Sigma_{22}b\\\\\n",
    "Cov(U,V) &= a^T Cov(X^1,X^2)b = a^T \\Sigma_{12}b\n",
    "\\end{align*}\n",
    "\n",
    "We seek coefficient vectors a and b such that\n",
    "\n",
    "$Corr(U,V) = \\frac{a^T\\Sigma_{12}b}{\\sqrt{a^T\\Sigma_{11}a}\\sqrt{b^T\\Sigma_{22}b}}$\n",
    "is as large as possible.\n",
    "\n",
    "Variance of U and V = 1.\n",
    "\n",
    "\n",
    "Define:\n",
    "\n",
    "kth canonical variate pair = the pair of linear combination $U_k$ and $V_k$ having\n",
    "unit variances, which maximize the correlation among all ** choices uncorrelated with\n",
    "the previous k - 1 canonical variate pairs.** Note: uncorrelated does not equal to independent!\n",
    "\n",
    "<img src=\"eig.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Result:\n",
    "\n",
    "$Max_{a,b} Corr(U,V) = \\rho^*_1$\n",
    "\n",
    "attained by the linear combinations\n",
    "\n",
    "$U_1 = e_1^T \\Sigma_{11}^{-1/2}X^1$ and $V_1 = f_1^T \\Sigma_{22}^{-1/2} X^2$\n",
    "\n",
    "The canonical variates have the properties\n",
    "$Var(U_k) = Var(V_k) = 1$\n",
    "\n",
    "$Cov(U_k,U_l) = Cov(V_k,V_l) = Cov(U_k,V_l) = 0$ when $k != l$\n",
    "\n",
    "### Canonical variates from standardized variables\n",
    "\n",
    "$Z^1 = [Z_1^1,Z_2^1,...,Z_p^1]^T$ and\n",
    "\n",
    "$Z^2 = [Z_1^2, Z_2^2,...,Z_q^2]^T$\n",
    "\n",
    "Here, $Cov(Z^1) = \\rho_{11}, Cov(Z^2) = \\rho_{22}$, and\n",
    "\n",
    "$Cov(Z^1,Z^2) = \\rho_{12}=\\rho_{21}^T$.\n",
    "\n",
    "Then use\n",
    "$\\rho_{11}^{-1/2}\\rho_{12}\\rho_{22}^{-1}\\rho_{21}\\rho_{11}^{-1/2}$\n",
    "find eigenvalues and eigenvectors. Eigenvalues are the same as before but the eigenvectors are different.\n",
    "\n",
    "<img src=\"z.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "$a^T_k(X^1-\\mu^1) = a_k^T V_{11}^{1/2}Z^1$\n",
    "where $V_{11}$ is the diagonal matrix with ith element $Var(X_i^1)$.\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "Look at the linear combinatin: $U_1 = a_{11}X_1^1 + a_{12}X_2^1+..$\n",
    "1. $Corr(U_1, X_1^1)$... Here the correlation != the coefficient\n",
    "\n",
    "Note p.18:\n",
    "$\\rho_{U,X^1} = Corr(U,X^1) = I^{-1/2}Cov(U,X^1)V_{11}^{-1/2} = A\\Sigma_{11}V_{11}^{-1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "import scipy.linalg as la\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var_single(X):\n",
    "    \"\"\"\n",
    "    Find variance matrix\n",
    "    \"\"\"\n",
    "    v = np.cov(X)\n",
    "    r = np.matrix('v,1;1,v')\n",
    "    return r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://users.stat.umn.edu/~helwig/notes/cancor-Notes.pdf\n",
    "reference of R code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cca(X,Y):\n",
    "    \"\"\"\n",
    "    Canonical Correlatio Analysis\n",
    "    \n",
    "    Input:\n",
    "    X: observation matrix X, every column is one data point\n",
    "    Y: observation matrix Y, every column is one data point\n",
    "    \n",
    "    Output:\n",
    "    basis in X space, basis in Y space, correlation\n",
    "    \"\"\"\n",
    "    # find variance and covariance matrix\n",
    "    if len(X) == 1:\n",
    "        cov_xx = var_single(X)\n",
    "    else:\n",
    "        cov_xx = np.cov(X)\n",
    "    if len(Y) == 1:\n",
    "        cov_yy = var_single(Y)\n",
    "    else:\n",
    "        cov_yy = np.cov(Y)\n",
    "    n = len(X)\n",
    "\n",
    "    cov_xy = np.cov(X, Y)[:n,n:]    \n",
    "    cov_yx = np.transpose(cov_xy)\n",
    "    # eigen\n",
    "    cov_xx_evalue,cov_xx_evector = la.eig(cov_xx)\n",
    "    cov_xx_isqrt = dot(dot(cov_xx_evector,np.diag(1/np.sqrt(cov_xx_evalue))),np.transpose(cov_xx_evector))\n",
    "    \n",
    "    cov_yy_evalue, cov_yy_evector = la.eig(cov_yy)\n",
    "    cov_yy_isqrt = dot(dot(cov_yy_evector,np.diag(1/np.sqrt(cov_yy_evalue))), np.transpose(cov_yy_evector))\n",
    "    a = la.inv(cov_yy)\n",
    "    # Xmat and Ymat\n",
    "    Xmat = dot(dot(dot(dot(cov_xx_isqrt,cov_xy),la.inv(cov_yy)),cov_yx),cov_xx_isqrt)\n",
    "    ymat = dot(dot(dot(dot(cov_yy_isqrt,cov_yx),la.inv(cov_xx)),cov_xy),cov_yy_isqrt)\n",
    "    \n",
    "    r1=la.eig(Xmat)\n",
    "    r2=la.eig(Ymat)\n",
    "    \n",
    "    return r1,r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[-11.25,7.43, 15.48, 2.27, -48.90, -15.13, 49.28, 4.7, 61.32, -268.95, 8488]\n",
    "b=[-10.87, 7.45, 14.97, 1.97, -47.71, -14.46, 44.36, 5.1, 61.76, -273.02, 8399]\n",
    "c=[-11.18, 7.44, 14.20, 1.97, -48.29, -14.81, 43.66, 5.2, 64.16, -263.20, 8328]\n",
    "d=[-10.62, 7.38, 15.02, 2.03, -49.06, -14.72, 44.80, 4.9, 64.04, -285.11, 8306]\n",
    "e=[-11.02, 7.43, 12.92, 1.97, -47.44, -14.40, 41.20, 5.2, 57.46, -256.64, 8286]\n",
    "f=[-10.83, 7.72, 13.58, 2.12, -48.34, -14.18, 43.06, 4.9, 52.18, -274.07, 8272]\n",
    "g=[-11.18, 7.05, 14.12, 2.06, -49.34, -14.39, 41.68, 5.7, 61.60, -291.20, 8216]\n",
    "h=[-11.05, 6.95, 15.34, 2.00, -48.21, -14.36, 41.32, 4.8, 63.00, -265.86, 8189]\n",
    "i=[-11.15, 7.12, 14.52, 2.03, -49.15, -14.66, 42.36,4.9, 66.46, -269.62, 8180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.vstack((a,b,c,d,e,f,g,h,i))\n",
    "run100=data[:,0]\n",
    "long_jump = data[:,1]\n",
    "shot = data[:,2]\n",
    "high_jump = data[:,3]\n",
    "run400 = data[:,4]\n",
    "hurdle = data[:,5]\n",
    "discus = data[:,6]\n",
    "pole_vault = data[:,7]\n",
    "javelin = data[:,8]\n",
    "run1500 = data[:,9]\n",
    "score = data[:,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X: shot, discus, javelin, pole_vault\n",
    "\n",
    "Y: run100,run400,run1500,hurdle,long_jump,high_jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.vstack((shot, discus, javelin,pole_vault))\n",
    "Y = np.vstack((run100, run400,run1500,hurdle,long_jump,high_jump))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1,r2=cca(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.60595938+0.j,  0.94686012+0.j,  1.00000000+0.j,  1.00000000+0.j])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77843392+0.j,  0.97306738+0.j,  1.00000000+0.j,  1.00000000+0.j])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(r1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.78433925e-01 +0.00000000e+00j,\n",
       "         9.73067377e-01 +0.00000000e+00j,\n",
       "         0.00000000e+00 +7.82039080e-09j,\n",
       "         1.42187762e-08 +0.00000000e+00j,\n",
       "         1.00000000e+00 +0.00000000e+00j,   1.00000000e+00 +0.00000000e+00j])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(r2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CCA_Mardia(H1, H2, dim):\n",
    "    # H1 and H2 are NxD matrices containing samples rowwise.\n",
    "    # dim is the desired dimensionality of CCA space.\n",
    "    \n",
    "    d1 = H1.shape[0]\n",
    "    d2 = H2.shape[0]\n",
    "    N = H1.shape[1]\n",
    "    \n",
    "    # Remove mean\n",
    "    m1 = np.mean(H1, axis=1)\n",
    "    m2 = np.mean(H2, axis=1)\n",
    "    H1 = H1 - np.reshape(m1,(d1,1))\n",
    "    H2 = H2 - np.reshape(m2,(d2,1))\n",
    "    \n",
    "    S11 = (dot(H1,np.transpose(H1)))/(N-1)\n",
    "    S22 = (dot(H2,np.transpose(H2)))/(N-1)\n",
    "    S12 = (dot(H2,np.transpose(H1)))/(N-1)\n",
    "\n",
    "    D1,V1 = la.eig(S11)\n",
    "    D2,V2 = la.eig(S22)\n",
    "\n",
    "    K11 = dot(dot(V1,np.diag(1/np.sqrt(D1))),np.transpose(V1))\n",
    "    K22 = dot(dot(V2,np.diag(1/np.sqrt(D2))),np.transpose(V2))\n",
    "\n",
    "    T = dot(dot(K22,S12),K11)\n",
    "    U,D,V = np.linalg.svd(T)\n",
    "    D = np.diag(D)\n",
    "    A = dot(K11,np.transpose(V[0:dim,:]))\n",
    "    B = dot(K22,np.transpose(U[0:dim,:]))\n",
    "    D = D[0:dim]\n",
    "    return A,B,D\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.50316581+0.j, -0.06281345+0.j,  1.15987226+0.j, -1.65332289+0.j],\n",
       "        [ 0.08255531+0.j,  0.43747610+0.j, -0.16197003+0.j,  0.21997911+0.j],\n",
       "        [ 0.09600330+0.j, -0.07034461+0.j, -0.28120598+0.j,  0.12058579+0.j],\n",
       "        [ 3.14622143+0.j,  0.95045772+0.j,  2.57226974+0.j,  0.45561675+0.j]]),\n",
       " array([[ -4.55381457+0.j,  -0.09639920+0.j,  -2.47922391+0.j,\n",
       "          -2.28782268+0.j],\n",
       "        [ -0.57626866+0.j,  -0.31004618+0.j,   0.25704203+0.j,\n",
       "          -1.48204993+0.j],\n",
       "        [ -0.06972073+0.j,   0.04958413+0.j,  -0.05069234+0.j,\n",
       "           0.10586283+0.j],\n",
       "        [ -1.48079963+0.j,  -0.90421183+0.j,   0.90758005+0.j,\n",
       "           1.80893553+0.j],\n",
       "        [  4.35535280+0.j,  -0.48420844+0.j,  -2.63676550+0.j,\n",
       "           1.37758996+0.j],\n",
       "        [-10.17707404+0.j,  -9.41804996+0.j,   0.30837624+0.j,\n",
       "           2.20140784+0.j]]),\n",
       " array([[ 1.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  1.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.97306738,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.77843392]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CCA_Mardia(X,Y,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, both method yields same canonical correlation:\n",
    "\n",
    "**1,1,0.973,0.778**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Canonical Correlation Analysis\n",
    "\n",
    "Kernel CCA offers an alternative solution by first projecting the data into a higher-dimensional feature space.\n",
    "\n",
    "$\\Phi: x = (x_1,...,x_m) \\to \\Phi(x) = (\\Phi_1(x),...,\\Phi_N(x)) (m<N)$\n",
    "\n",
    "Kernel is known as the kernel trick. A kernel is a function K, such that for all x,z in X, \n",
    "\n",
    "$K(x,z) = <\\Phi(x)*\\Phi(z)>$,\n",
    "\n",
    "where $\\Phi$ is a mapping from X to a feature space F.\n",
    "\n",
    "We can rewrite the covariance matrix C using the data matrices X and Y, which have the sample vector as rows and are therefore of size m by N; we obtain\n",
    "\n",
    "$C_{xx} = X'X, C_{xy}=X'Y$.\n",
    "\n",
    "Then $w_{x(N*1)} = X_{N*m}'\\alpha_{m*1}, w_{y(N*1)}=Y_{N*m}'\\beta_{m*1}$.\n",
    "\n",
    "So $\\rho = max_{\\alpha,\\beta} \\frac{\\alpha'XX'YY'\\beta}{\\sqrt{\\alpha'XX'XX'\\alpha * \\beta'YY'YY'\\beta}}$\n",
    "\n",
    "Let $K_x = XX', K_y = YY'$ be the kernel matrices, we have\n",
    "\n",
    "$\\rho = max_{\\alpha,\\beta} \\frac{\\alpha'K_xK_y\\beta}{\\sqrt{\\alpha'K_x^2\\alpha \\beta'K_y^2\\beta}}$\n",
    "\n",
    "So it is equivalent to maxmizing the numerator subject to denominator = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## regularization\n",
    "\n",
    "It combine the PLS term with the KCCA term in the denominator, obtaining:\n",
    "\n",
    "$\\rho = max_{\\alpha,\\beta} \\frac{\\alpha'K_xK_y\\beta}{\\sqrt{(\\alpha'K_x^2\\alpha+k||w_x||^2)(\\beta'K^2_y\\beta+k||w_y||^2)}}\n",
    "=max_{\\alpha,\\beta} \\frac{\\alpha'K_xK_y\\beta}{\\sqrt{(\\alpha'K_x^2\\alpha+k\\alpha'K_x\\alpha)(\\beta'K^2_y\\beta+k\\beta'K_y\\beta)}}$\n",
    "\n",
    "obtain a standard eigenproblem of the form $Ax=\\lambda x$.\n",
    "\n",
    "## Partial Gram-Schmidt Orthogonalization\n",
    "\n",
    "Use PGSO as matrix decomposition approach.\n",
    "\n",
    "problem:\n",
    "KCCA involves and N by N eigenvalue problem and so is challenging in both memory and time (O(N3)). Several approximation methods have been proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Canonical Correlation Analysis\n",
    "\n",
    "Deep CCA computes representations of the two views by passing them\n",
    "through multiple stacked layers of nonlinear transformation.\n",
    "\n",
    "<img src=\"dnet.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "The goal is to jointly learn parameters for both views $W_l^v. b_l^v$ such that $corr(f_1(X_1),f_2(X_2))$ is as high as possible.\n",
    "\n",
    "$(\\theta_1^*,\\theta_2^*) = argmax_{\\theta_1,\\theta_2} corr(f_1(X_1),f_2(X_2))$\n",
    "\n",
    "To find $(\\theta_1^*,\\theta_2^*)$, we follow the gradient of the correlation objective as estimated on the training data.\n",
    "\n",
    "k = o, so the output is the number of top k components of H1 and H2.\n",
    "\n",
    "\n",
    "### Use L-BFGS second-order optimization method.\n",
    "\n",
    "### Non-saturating nonlinearity\n",
    "\n",
    "Best results are obtained by using $g(y)=g^3/3+y, s(x)=g^{-1}(x)$\n",
    "\n",
    "1. s is not bounded, and its derivative falls off much more gradually with x.\n",
    "2. it derivative is a simple function of its value\n",
    "\n",
    "Python code:https://github.com/VahidooX/DeepCCA\n",
    "\n",
    "Let's look at the loss function: y_pred is ignored, that is the\n",
    "reason it return **-corr. We want to maximize the correlation = minimize the loss(-corr).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "def cca_loss(outdim_size, use_all_singular_values):\n",
    "    \"\"\"\n",
    "    The main loss function (inner_cca_objective) is wrapped in this function due to\n",
    "    the constraints imposed by Keras on objective functions\n",
    "    \"\"\"\n",
    "    def inner_cca_objective(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        It is the loss function of CCA as introduced in the original paper. There can be other formulations.\n",
    "        It is implemented by Theano tensor operations, and does not work on Tensorflow backend\n",
    "        y_true is just ignored\n",
    "        \"\"\"\n",
    "\n",
    "        r1 = 1e-4\n",
    "        r2 = 1e-4\n",
    "        eps = 1e-12\n",
    "        o1 = o2 = y_pred.shape[1]//2\n",
    "\n",
    "        # unpack (separate) the output of networks for view 1 and view 2\n",
    "        H1 = y_pred[:, 0:o1].T\n",
    "        H2 = y_pred[:, o1:o1+o2].T\n",
    "\n",
    "        m = H1.shape[1]\n",
    "\n",
    "        H1bar = H1 - (1.0 / m) * T.dot(H1, T.ones([m, m]))\n",
    "        H2bar = H2 - (1.0 / m) * T.dot(H2, T.ones([m, m]))\n",
    "\n",
    "        SigmaHat12 = (1.0 / (m - 1)) * T.dot(H1bar, H2bar.T)\n",
    "        SigmaHat11 = (1.0 / (m - 1)) * T.dot(H1bar, H1bar.T) + r1 * T.eye(o1)\n",
    "        SigmaHat22 = (1.0 / (m - 1)) * T.dot(H2bar, H2bar.T) + r2 * T.eye(o2)\n",
    "\n",
    "        # Calculating the root inverse of covariance matrices by using eigen decomposition\n",
    "        [D1, V1] = T.nlinalg.eigh(SigmaHat11)\n",
    "        [D2, V2] = T.nlinalg.eigh(SigmaHat22)\n",
    "\n",
    "        # Added to increase stability\n",
    "        posInd1 = T.gt(D1, eps).nonzero()[0]\n",
    "        D1 = D1[posInd1]\n",
    "        V1 = V1[:, posInd1]\n",
    "        posInd2 = T.gt(D2, eps).nonzero()[0]\n",
    "        D2 = D2[posInd2]\n",
    "        V2 = V2[:, posInd2]\n",
    "\n",
    "        SigmaHat11RootInv = T.dot(T.dot(V1, T.nlinalg.diag(D1 ** -0.5)), V1.T)\n",
    "        SigmaHat22RootInv = T.dot(T.dot(V2, T.nlinalg.diag(D2 ** -0.5)), V2.T)\n",
    "\n",
    "        Tval = T.dot(T.dot(SigmaHat11RootInv, SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "        if use_all_singular_values:\n",
    "            # all singular values are used to calculate the correlation\n",
    "            corr = T.sqrt(T.nlinalg.trace(T.dot(Tval.T, Tval)))\n",
    "        else:\n",
    "            # just the top outdim_size singular values are used\n",
    "            [U, V] = T.nlinalg.eigh(T.dot(Tval.T, Tval))\n",
    "            U = U[T.gt(U, eps).nonzero()[0]]\n",
    "            U = U.sort()\n",
    "            corr = T.sum(T.sqrt(U[0:outdim_size]))\n",
    "\n",
    "        return -corr\n",
    "\n",
    "    return inner_cca_objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "it uses sigmoid activation function instead of the one in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Merge\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l2\n",
    "from objectives import cca_loss\n",
    "\n",
    "\n",
    "def create_model(layer_sizes1, layer_sizes2, input_size1, input_size2,\n",
    "                    learning_rate, reg_par, outdim_size, use_all_singular_values):\n",
    "    \"\"\"\n",
    "    builds the whole model\n",
    "    the structure of each sub-network is defined in build_mlp_net,\n",
    "    and it can easily get substituted with a more efficient and powerful network like CNN\n",
    "    \"\"\"\n",
    "    view1_model = build_mlp_net(layer_sizes1, input_size1, reg_par)\n",
    "    view2_model = build_mlp_net(layer_sizes2, input_size2, reg_par)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([view1_model, view2_model], mode='concat'))\n",
    "\n",
    "    model_optimizer = RMSprop(lr=learning_rate)\n",
    "    model.compile(loss=cca_loss(outdim_size, use_all_singular_values), optimizer=model_optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_mlp_net(layer_sizes, input_size, reg_par):\n",
    "    model = Sequential()\n",
    "    for l_id, ls in enumerate(layer_sizes):\n",
    "        if l_id == 0:\n",
    "            input_dim = input_size\n",
    "        else:\n",
    "            input_dim = []\n",
    "        if l_id == len(layer_sizes)-1:\n",
    "            activation = 'linear'\n",
    "        else:\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        model.add(Dense(ls, input_dim=input_dim,\n",
    "                                activation=activation,\n",
    "                                kernel_regularizer=l2(reg_par)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ############\n",
    "    # Parameters Section\n",
    "\n",
    "    # the path to save the final learned features\n",
    "    save_to = './new_features.gz'\n",
    "\n",
    "    # the size of the new space learned by the model (number of the new features)\n",
    "    outdim_size = 10\n",
    "\n",
    "    # size of the input for view 1 and view 2\n",
    "    input_shape1 = 784\n",
    "    input_shape2 = 784\n",
    "\n",
    "    # number of layers with nodes in each one\n",
    "    layer_sizes1 = [1024, 1024, 1024, outdim_size]\n",
    "    layer_sizes2 = [1024, 1024, 1024, outdim_size]\n",
    "\n",
    "    # the parameters for training the network\n",
    "    learning_rate = 1e-3\n",
    "    epoch_num = 100\n",
    "    batch_size = 800\n",
    "\n",
    "    # the regularization parameter of the network\n",
    "    # seems necessary to avoid the gradient exploding especially when non-saturating activations are used\n",
    "    reg_par = 1e-5\n",
    "\n",
    "    # specifies if all the singular values should get used to calculate the correlation or just the top outdim_size ones\n",
    "    # if one option does not work for a network or dataset, try the other one\n",
    "    use_all_singular_values = False\n",
    "\n",
    "    # if a linear CCA should get applied on the learned features extracted from the networks\n",
    "    # it does not affect the performance on noisy MNIST significantly\n",
    "    apply_linear_cca = True\n",
    "\n",
    "    # end of parameters section\n",
    "    ############\n",
    "\n",
    "    # Each view is stored in a gzip file separately. They will get downloaded the first time the code gets executed.\n",
    "    # Datasets get stored under the datasets folder of user's Keras folder\n",
    "    # normally under [Home Folder]/.keras/datasets/\n",
    "    data1 = load_data('noisymnist_view1.gz', 'https://www2.cs.uic.edu/~vnoroozi/noisy-mnist/noisymnist_view1.gz')\n",
    "    data2 = load_data('noisymnist_view2.gz', 'https://www2.cs.uic.edu/~vnoroozi/noisy-mnist/noisymnist_view2.gz')\n",
    "\n",
    "    # Building, training, and producing the new features by DCCA\n",
    "    model = create_model(layer_sizes1, layer_sizes2, input_shape1, input_shape2,\n",
    "                            learning_rate, reg_par, outdim_size, use_all_singular_values)\n",
    "    model.summary()\n",
    "    model = train_model(model, data1, data2, epoch_num, batch_size)\n",
    "    new_data = test_model(model, data1, data2, outdim_size, apply_linear_cca)\n",
    "\n",
    "    # Training and testing of SVM with linear kernel on the view 1 with new features\n",
    "    [test_acc, valid_acc] = svm_classify(new_data, C=0.01)\n",
    "    print(\"Accuracy on view 1 (validation data) is:\", valid_acc * 100.0)\n",
    "    print(\"Accuracy on view 1 (test data) is:\", test_acc*100.0)\n",
    "\n",
    "    # Saving new features in a gzip pickled file specified by save_to\n",
    "    print('saving new features ...')\n",
    "    f1 = gzip.open(save_to, 'wb')\n",
    "    thepickle.dump(new_data, f1)\n",
    "    f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from utils import load_data, svm_classify\n",
    "from linear_cca import linear_cca\n",
    "from models import create_model\n",
    "\n",
    "\n",
    "def train_model(model, data1, data2, epoch_num, batch_size):\n",
    "    \"\"\"\n",
    "    trains the model\n",
    "    # Arguments\n",
    "        data1 and data2: the train, validation, and test data for view 1 and view 2 respectively. data should be packed\n",
    "        like ((X for train, Y for train), (X for validation, Y for validation), (X for test, Y for test))\n",
    "        epoch_num: number of epochs to train the model\n",
    "        batch_size: the size of batches\n",
    "    # Returns\n",
    "        the trained model\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpacking the data\n",
    "    train_set_x1, train_set_y1 = data1[0]\n",
    "    valid_set_x1, valid_set_y1 = data1[1]\n",
    "    test_set_x1, test_set_y1 = data1[2]\n",
    "\n",
    "    train_set_x2, train_set_y2 = data2[0]\n",
    "    valid_set_x2, valid_set_y2 = data2[1]\n",
    "    test_set_x2, test_set_y2 = data2[2]\n",
    "\n",
    "    # best weights are saved in \"temp_weights.hdf5\" during training\n",
    "    # it is done to return the best model based on the validation loss\n",
    "    checkpointer = ModelCheckpoint(filepath=\"temp_weights.h5\", verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    # used dummy Y because labels are not used in the loss function\n",
    "    model.fit([train_set_x1, train_set_x2], np.zeros(len(train_set_x1)),\n",
    "              batch_size=batch_size, epochs=epoch_num, shuffle=True,\n",
    "              validation_data=([valid_set_x1, valid_set_x2], np.zeros(len(valid_set_x1))),\n",
    "              callbacks=[checkpointer])\n",
    "\n",
    "    model.load_weights(\"temp_weights.h5\")\n",
    "\n",
    "    results = model.evaluate([test_set_x1, test_set_x2], np.zeros(len(test_set_x1)), batch_size=batch_size, verbose=1)\n",
    "\n",
    "    print('loss on test data: ', results)\n",
    "\n",
    "    results = model.evaluate([valid_set_x1, valid_set_x2], np.zeros(len(valid_set_x1)), batch_size=batch_size, verbose=1)\n",
    "    print('loss on validation data: ', results)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, data1, data2, outdim_size, apply_linear_cca):\n",
    "    \"\"\"produce the new features by using the trained model\n",
    "    # Arguments\n",
    "        model: the trained model\n",
    "        data1 and data2: the train, validation, and test data for view 1 and view 2 respectively.\n",
    "            Data should be packed like\n",
    "            ((X for train, Y for train), (X for validation, Y for validation), (X for test, Y for test))\n",
    "        outdim_size: dimension of new features\n",
    "        apply_linear_cca: if to apply linear CCA on the new features\n",
    "    # Returns\n",
    "        new features packed like\n",
    "            ((new X for train - view 1, new X for train - view 2, Y for train),\n",
    "            (new X for validation - view 1, new X for validation - view 2, Y for validation),\n",
    "            (new X for test - view 1, new X for test - view 2, Y for test))\n",
    "    \"\"\"\n",
    "\n",
    "    # producing the new features\n",
    "    new_data = []\n",
    "    for k in range(3):\n",
    "        pred_out = model.predict([data1[k][0], data2[k][0]])\n",
    "        r = int(pred_out.shape[1] / 2)\n",
    "        new_data.append([pred_out[:, :r], pred_out[:, r:], data1[k][1]])\n",
    "\n",
    "    # based on the DCCA paper, a linear CCA should be applied on the output of the networks because\n",
    "    # the loss function actually estimates the correlation when a linear CCA is applied to the output of the networks\n",
    "    # however it does not improve the performance significantly\n",
    "    if apply_linear_cca:\n",
    "        w = [None, None]\n",
    "        m = [None, None]\n",
    "        print(\"Linear CCA started!\")\n",
    "        w[0], w[1], m[0], m[1] = linear_cca(new_data[0][0], new_data[0][1], outdim_size)\n",
    "        print(\"Linear CCA ended!\")\n",
    "\n",
    "        # Something done in the original MATLAB implementation of DCCA, do not know exactly why;)\n",
    "        # it did not affect the performance significantly on the noisy MNIST dataset\n",
    "        #s = np.sign(w[0][0,:])\n",
    "        #s = s.reshape([1, -1]).repeat(w[0].shape[0], axis=0)\n",
    "        #w[0] = w[0] * s\n",
    "        #w[1] = w[1] * s\n",
    "        ###\n",
    "\n",
    "        for k in range(3):\n",
    "            data_num = len(new_data[k][0])\n",
    "            for v in range(2):\n",
    "                new_data[k][v] -= m[v].reshape([1, -1]).repeat(data_num, axis=0)\n",
    "                new_data[k][v] = np.dot(new_data[k][v], w[v])\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svm_classify\n",
    "\n",
    "new features packed like：\n",
    "1. ((new X for train - view 1, new X for train - view 2, Y for train),\n",
    "2. (new X for validation - view 1, new X for validation - view 2, Y for validation),\n",
    "3. (new X for test - view 1, new X for test - view 2, Y for test))\n",
    "\n",
    "svm（train view1, Y for train) -> view 1 feature and Y for train image\n",
    "\n",
    "svm predict(test view1) -> Y' and compare with Y for test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import theano\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "def svm_classify(data, C):\n",
    "    \"\"\"\n",
    "    trains a linear SVM on the data\n",
    "    input C specifies the penalty factor of SVM\n",
    "    \"\"\"\n",
    "    train_data, _, train_label = data[0]\n",
    "    valid_data, _, valid_label = data[1]\n",
    "    test_data, _, test_label = data[2]\n",
    "\n",
    "    print('training SVM...')\n",
    "    clf = svm.LinearSVC(C=C, dual=False)\n",
    "    clf.fit(train_data, train_label.ravel())\n",
    "\n",
    "    p = clf.predict(test_data)\n",
    "    test_acc = accuracy_score(test_label, p)\n",
    "    p = clf.predict(valid_data)\n",
    "    valid_acc = accuracy_score(valid_label, p)\n",
    "\n",
    "    return [test_acc, valid_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep canonically correlated autoencoders (DCCAE)\n",
    "\n",
    "### multiple views of data at training time while only one view is available at test time:\n",
    "\n",
    "1. audio + video\n",
    "2. audio + atriculation\n",
    "3. images + text\n",
    "4. parallel text in two languages\n",
    "5. words + context\n",
    "6. document txt + text of inbound hyperlinks\n",
    "\n",
    "This presents an opportunity to learn better representations by analyzing multip;e views simultaneously.\n",
    "\n",
    "Typical approach: learning a feature transformation of the primary view that captures useful information from the second view using a paired two-view training set.\n",
    "\n",
    "1. auotoencoders: the objective is to learn a compact representation that best reconstructs the inputs\n",
    "2. CCA: learns features in two views that are maximally correlated\n",
    "\n",
    "### Split autoencoders (SplitAE)\n",
    "\n",
    "extract shared reprensentations by reconstructing both views from the one view that is available at test time. feature extraction network f is shared while the reconstruction network p and q are separate for each view.\n",
    "\n",
    "object is the sum of reconstruction errors for the two views:\n",
    "$min_{w_f,w_p,w_q} 1/N \\sum_{i=1}^N (||x_i - p(f(x_i))||^2 + ||y_i-q(g(x_i))||^2)$\n",
    "<img src=\"splitae.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "### DCCAE\n",
    "\n",
    "object:\n",
    "$min_{w_f,w_g,w_p,w_q,U,V} -1/N tr(U^Tf(X)g(Y)^TV) + \\lambda/N \\sum_{i=1}^N (||x_i - p(f(x_i))||^2 + ||y_i-q(g(x_i))||^2)$\n",
    "\n",
    "<img src=\"dccae.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "CCA maximizes the mutual information between the projected views for certain distributions;\n",
    "\n",
    "Autoencoder minimizes reconstruction error amounts to maximizing a lower bound on the mutual information between inputs and learned features.\n",
    "\n",
    "#### Minimum-distance autoencoders (DistAE)\n",
    "The CCA objective can be seen as minimizing the distance between the learned projections of the two views, while stisfying the whitening constraints for the projections. The constraints complicate the optimization of CCA-based objectives.\n",
    "\n",
    "object:\n",
    "$min_{w_f,w_g,w_p,w_q,U,V} -1/N \\sum_{i=1}^N \\frac{||f(x_i)-g(y_i)||^2}{||f(x_i)||^2+||g(y_i)||^2}+ \\lambda/N \\sum_{i=1}^N (||x_i - p(f(x_i))||^2 + ||y_i-q(g(x_i))||^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Variational Canonical Correlation Analysis (VCCA)\n",
    "\n",
    "A deep multi-view learning model that extends the latent variable model interpretation of linear CCA to nonlinear observation models parameterized by DNN.\n",
    "\n",
    "Probabilistic latent variable model interpretation of CCA:\n",
    "<img src=\"lat.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "x and y are linear functions of some random variable z. the prior distribution p(z) and conditional distributions p(x|z) and p(y|z) are Gaussian.\n",
    "\n",
    "Jordan showed that E[z|x] lives in the same space as the linear CCA projection for x.\n",
    "\n",
    "** This generative interpretation of CCA is often lost in its nonlinear extensions**.\n",
    "\n",
    "### Disadvantage of DCCA:\n",
    "1. Its objective couples all training samples together and is hard to optimize with SGD;\n",
    "2. It focuses on extracting the shared information only, while there may also be useful view-specific information that we wish to retain;\n",
    "3. It does not provide a model for generating samples from the latent space. Although Wang's DCCAE optimizes the combination of an autoencoder and cca objective, they found in practice, the cca objective dominate the reconstruction term, so the inputs are not reconstructed well.\n",
    "\n",
    "\n",
    "## VCCA:\n",
    "<img src=\"vcca.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "$p(x,y,z) = p(z)p(x|z)p(y|z), p(x,y) = \\int p(x,y,z)dz$\n",
    "\n",
    "The two views x and y are conditionally independent on the latent varianles z. Here, it consider non linear observation models $p_\\theta(x|z;\\theta_x)$ and $p_\\theta(y|z;\\theta_y)$. So marginal likelihood $p_\\theta(x,y)$ does not have a closed form, and the inference problem $p_\\theta(z|x)$ is also intractable.\n",
    "\n",
    "Approximating $p_\\theta(z|x) $ with the conditional density $q_\\Phi(z|x;\\Phi_z)$, where $\\Phi_z$ is the collection of parameters of another DNN.\n",
    "\n",
    "We can derive a lower bound on the marginal data log-likelihood and VCCA maximizes this variational lower bound on the data log-likelihood on the training set:\n",
    "\n",
    "**object:**\n",
    "\n",
    "$max_{\\theta,\\Phi} 1/N \\sum_{i=1}^N L(x_i,y_i;\\theta,\\Phi)$\n",
    "\n",
    "$logp_\\theta(x,y) >= L(x,y;\\theta,\\Phi) := - D_{KL}(q_\\Phi(z|x)||p(z)) + E{q_\\Phi(z|x)}[logp_\\theta(x|z)+logp_\\theta(y|z)]$\n",
    "\n",
    "**KL divergence term:**\n",
    "\n",
    "$D_{KL}(q_\\Phi(z|x)||p(z)) = -0.5 \\sum_{j=1}^{d_z} (1+log \\sigma_{ij}^2 -\\sigma_{ij}^2 - \\mu_{ij}^2)$\n",
    "\n",
    "**expected log-likelihood term:**\n",
    "\n",
    "$E{q_\\Phi(z|x)}[logp_\\theta(x|z)+logp_\\theta(y|z)]\\approx 1/L \\sum_{l=1}^L log p_\\theta(x_i|z_i^l) + log p_\\theta(y_i|z_i^l)$\n",
    "\n",
    "### Disadvantage of VCCA:\n",
    "It assumes the common latent variables z are sufficient to generate the views. There might be large variations in the input space that can not be explained by the common variables.\n",
    "## VCCA-private\n",
    "<img src=\"vcca-p.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "$p(x,y,z,h_x,h_y) = p(z)p(h_x)p(h_y)p_\\theta(x|z,h_x;\\theta_x)p_\\theta(y|z,h_y;\\theta_y), p_\\theta(x,y) = \\int\\int\\int p_\\theta(x,y,z,h_x,h_y)dzdh_xdh_y$\n",
    "\n",
    "$q_\\Phi(z,h_x,h_y|x,y) = q_\\phi(z|x;\\Phi_z)q_\\Phi(h_x|x;\\Phi_x)q_\\Phi(h_y|y;\\Phi_y).$\n",
    "\n",
    "**object:**\n",
    "\n",
    "$max_{\\theta,\\Phi} 1/N \\sum_{i=1}^N L_{private}(x_i,y_i;\\theta,\\Phi)$\n",
    "\n",
    "$logp_\\theta(x,y) >= L(x,y;\\theta,\\Phi) := - D_{KL}(q_\\Phi(z|x)||p(z)) -D_{KL}(q_\\Phi(h_x|x)||p(h_x))-D_{KL}(q_\\Phi(h_y|y)||p(h_y)) + E{q_\\Phi(z|x)q_\\Phi(h_x|x)}[logp_\\theta(x|z,h_x)]+E_{q\\Phi(z|x),q_\\Phi(h_y|y)}[logp_\\theta(y|z)]$\n",
    "\n",
    "\n",
    "**The private variables contain little class information but mainly style information**\n",
    "\n",
    "<img src=\"style.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "# VCCA-p for acoustic feature learning\n",
    "\n",
    "Apply VCCA and VCCA-p on the X-ray Microbeam Database.\n",
    "\n",
    "acoustic:\n",
    "<img src=\"acous.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "articulatory:\n",
    "<img src=\"art.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "## Generative adversrial training\n",
    "\n",
    "We extend VCCA/VCCAP with generative adversarial training by viewing the basic VCCA/VCCAP model as a pair of generators, and adding two discriminators D1 and D2, one for each view, which try to distinguish the generated samples from training set unput samples.\n",
    "<img src=\"vccapg.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "D1 optimizes:\n",
    "\n",
    "$max_{D1} logD_1(x_i)+log(1-D1(x_i'))$, \n",
    "\n",
    "where x is the original input of the first view and x' is the corresponding reconstruction.\n",
    "\n",
    "The generator optimize:\n",
    "\n",
    "$max_{\\theta,\\Phi} L_{private}(x_i,y_i;\\theta,\\Phi) + \\lambda_1log(D1(x_i'))+\\lambda_2log(D2(y_i'))$\n",
    "\n",
    "## Code for VCCA class in tensorflow\n",
    "\n",
    "See https://github.com/edchengg/VCCA-StudyNotes/tree/master/qingming_tang-interspeech2017_vccap-fad4faebbc4b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
